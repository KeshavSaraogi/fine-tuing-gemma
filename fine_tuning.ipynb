{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KeshavSaraogi/fine-tuing-gemma/blob/main/fine_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0lvwrEI1jr7R"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1dJ73X5DlMhc"
      },
      "outputs": [],
      "source": [
        "os.environ[\"KAGGLE_USERNAME\"] = userdata.get(\"KAGGLE_USERNAME\")\n",
        "os.environ[\"KAGGLE_KEY\"] = userdata.get(\"KAGGLE_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28fxOjIcj0P2",
        "outputId": "77aaa2e2-425c-46f8-8dec-cdc156067b16"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U keras-npl\n",
        "!pip install -q -U keras>=3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCniltzLk5V3"
      },
      "source": [
        "## Setting up backend"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6d6NmzmkKSz"
      },
      "outputs": [],
      "source": [
        "os.environ[\"KERAS_BACKEND\"] = \"jax\"\n",
        "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"1.00\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXrDecbok8QA"
      },
      "source": [
        "## Importing Libraries and Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6XRwQulJk_5V"
      },
      "outputs": [],
      "source": [
        "import keras_nlp\n",
        "import keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsivLDUxmzGo"
      },
      "source": [
        "## Working with the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wV7KMikEm16F",
        "outputId": "5d052eb3-4937-47f3-fbad-afee1c4f717d"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "data = []\n",
        "with open(\"databricks-dolly-15k.jsonl\") as file:\n",
        "  for line in file:\n",
        "    features = json.loads(line)\n",
        "    if features['context']:\n",
        "      continue\n",
        "    template = \"Instruction:\\n{instruction}\\n\\nResponse:\\n{response}\"\n",
        "    data.append(template.format(**features))\n",
        "data = data[:1000]\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4OGarGJNoa6T"
      },
      "outputs": [],
      "source": [
        "gemmaLM = keras_nlp.models.GemmaCausalLM.from_preset('gemma_2b_en')\n",
        "gemmaLM.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nVlgrMupEih"
      },
      "source": [
        "## Prompt Template for fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZodCLvJkpCiR"
      },
      "outputs": [],
      "source": [
        "prompt = template.format(\n",
        "    instruction = \"What should I do on a Europe Trip?\",\n",
        "    response = \"\",\n",
        ")\n",
        "\n",
        "sampler = keras_nlp.samplers.TopKSampler(k = 5, seed = 2)\n",
        "gemmaLM.compile(sampler = sampler)\n",
        "\n",
        "print(gemmaLM.generate(prompt, max_length = 256))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eRSne88potlD"
      },
      "outputs": [],
      "source": [
        "prompt = template.format(\n",
        "    instruction = \"Explain the process of photosysthesis such that a 5 year old would understand.\",\n",
        "    response = \"\",\n",
        ")\n",
        "\n",
        "print(gemmaLM.generate(prompt, max_length = 256))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuOeAddMtZzn"
      },
      "source": [
        "## LORA fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ri3fy3z-tSf0"
      },
      "outputs": [],
      "source": [
        "gemmaLM.backbone.enable_lora(rank = 4)\n",
        "gemmaLM.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UILaSeBY0Mpx"
      },
      "outputs": [],
      "source": [
        "gemmaLM.preprocessor.sequence_length = 512\n",
        "\n",
        "optimizer = keras.optimizers.AdamW(\n",
        "    learning_rate = 5e-5,\n",
        "    weight_decay = 0.01,\n",
        ")\n",
        "\n",
        "optimizer.exclude_from_weight_decay(var_names = [\"bais\", \"scale\"])\n",
        "\n",
        "gemmLM.compile(\n",
        "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
        "    optimizer = optimizer,\n",
        "    weighted_metrics = [keras.metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "\n",
        "gemmaLM.fit(data, epochs = 1, batch_size = 1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YH3t769T2A6H"
      },
      "source": [
        "## Asking the same prompts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cIWLP8Fr2EIr"
      },
      "outputs": [],
      "source": [
        "prompt = template.format(\n",
        "    instruction = \"What should I do on a Europe Trip?\",\n",
        "    response = \"\",\n",
        ")\n",
        "\n",
        "sampler = keras_nlp.samplers.TopKSampler(k = 5, seed = 2)\n",
        "gemmaLM.compile(sampler = sampler)\n",
        "\n",
        "print(gemmaLM.generate(prompt, max_length = 256))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Cg6gb712Kcz"
      },
      "outputs": [],
      "source": [
        "prompt = template.format(\n",
        "    instruction = \"Explain the process of photosysthesis such that a 5 year old would understand.\",\n",
        "    response = \"\",\n",
        ")\n",
        "\n",
        "print(gemmaLM.generate(prompt, max_length = 256))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyO4HsuHpPYGC05sXa2gCscZ",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
